{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f92178b",
   "metadata": {},
   "source": [
    "## Pandas Interview Questions\n",
    "---\n",
    "### Question 1: Creating a DataFrame\n",
    "\n",
    "Create a Pandas DataFrame from a dictionary that contains two lists: `Name` with values `['Alice', 'Bob']` and `Age` with values `[25, 30]`.\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4b796e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name  age\n",
      "0  Alice   25\n",
      "1    Bob   30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dic = {'name': ['Alice', 'Bob'], 'age': [25, 30]}\n",
    "df = pd.DataFrame(dic)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a2c639",
   "metadata": {},
   "source": [
    "### Question 2: Conditional Selection\n",
    "\n",
    "Given a DataFrame `df`, select all rows where the 'Score' column is greater than 80 and the 'Status' column is 'Passed'.\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "143ad882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Score  Status\n",
      "0    Dan     85  Passed\n",
      "1    Eva     92  Passed\n",
      "3  Grace     88  Passed\n"
     ]
    }
   ],
   "source": [
    "data = {'Name': ['Dan', 'Eva', 'Frank', 'Grace'],\n",
    "        'Score': [85, 92, 74, 88],\n",
    "        'Status': ['Passed', 'Passed', 'Failed', 'Passed']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "filtered_df = df[(df['Score'] > 80) & (df['Status'] == 'Passed')]\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bab4502",
   "metadata": {},
   "source": [
    "**Explanation:** Similar to NumPy, Pandas uses boolean indexing. Two conditions are created and combined with the logical AND operator ( `&` ). Each condition must be enclosed in parentheses due to operator precedence in Python.\n",
    "***\n",
    "### Question 3: Handling Missing Data\n",
    "\n",
    "You have a DataFrame `df` with `NaN` values in the 'Sales' column. How do you replace these `NaN` values with the mean of that same column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ac28b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Month  Sales\n",
      "0   Jan  200.0\n",
      "1   Feb  210.0\n",
      "2   Mar  210.0\n",
      "3   Apr  220.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiru\\AppData\\Local\\Temp\\ipykernel_2760\\3792641054.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Sales'].fillna(mean_sales, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = {'Month': ['Jan', 'Feb', 'Mar', 'Apr'], 'Sales': [200, 210, np.nan, 220]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "mean_sales = df['Sales'].mean()\n",
    "df['Sales'].fillna(mean_sales, inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed90a2b4",
   "metadata": {},
   "source": [
    "**Explanation:** First, the mean of the 'Sales' column is calculated, which automatically ignores `NaN` values. Then, the `.fillna()` method is used on the 'Sales' column to replace all `NaN`s with the calculated mean. `inplace=True` modifies the DataFrame directly.\n",
    "***\n",
    "### Question 4: Grouping and Aggregation\n",
    "\n",
    "Given a DataFrame of employee data with 'Department' and 'Salary' columns, how would you find the average salary for each department?\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b25a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department\n",
      "HR    61000.000000\n",
      "IT    87666.666667\n",
      "Name: Salary, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Department': ['HR', 'IT', 'HR', 'IT', 'IT'],\n",
    "        'Salary': [60000, 85000, 62000, 90000, 88000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "avg_salary_by_dept = df.groupby('Department')['Salary'].mean()\n",
    "\n",
    "print(avg_salary_by_dept)\n",
    "avg_salary_by_dept.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58304b00",
   "metadata": {},
   "source": [
    "**Explanation:** The `.groupby('Department')` method groups the DataFrame by unique values in the 'Department' column. Then, we select the 'Salary' column `['Salary']` and apply the `.mean()` aggregation function to calculate the average for each group.\n",
    "***\n",
    "### Question 5: Merging DataFrames\n",
    "\n",
    "You have two DataFrames: `df1` with columns `['user_id', 'name']` and `df2` with `['user_id', 'order_count']`. How do you perform an inner merge on `user_id` to combine them?\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adc6b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id   name  order_count\n",
      "0        1  Alice            5\n",
      "1        2    Bob            2\n",
      "   user_id     name  order_count\n",
      "0        1    Alice          NaN\n",
      "1        2      Bob          NaN\n",
      "2        3  Charlie          NaN\n",
      "3        1      NaN          5.0\n",
      "4        2      NaN          2.0\n",
      "5        4      NaN         10.0\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'user_id': [1, 2, 3], 'name': ['Alice', 'Bob', 'Charlie']})\n",
    "df2 = pd.DataFrame({'user_id': [1, 2, 4], 'order_count': [5, 2, 10]})\n",
    "\n",
    "df_merge = pd.merge(df1, df2, how = 'inner', on = 'user_id')\n",
    "df3 = pd.concat([df1, df2], ignore_index=True) # Stacking vertically (default axis=0)\n",
    "\n",
    "print(df_merge)\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2275a0",
   "metadata": {},
   "source": [
    "**Explanation:** `pd.merge()` is the standard function for joining DataFrames. `on='user_id'` specifies the common column to join on, and `how='inner'` ensures that only `user_id`s present in *both* DataFrames are included in the result.\n",
    "***\n",
    "### Question 6: Adding a New Column\n",
    "\n",
    "Given a DataFrame with 'Price' and 'Quantity' columns, how do you create a new column called 'Total' which is the product of 'Price' and 'Quantity'?\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a83495e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Price  Quantity  Total\n",
      "0   10.0         3   30.0\n",
      "1    5.5         4   22.0\n",
      "2    8.0         5   40.0\n"
     ]
    }
   ],
   "source": [
    "data = {'Price': [10.0, 5.5, 8.0], 'Quantity': [3, 4, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['Total'] = df['Price'] * df['Quantity']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46613962",
   "metadata": {},
   "source": [
    "**Explanation:** You can create a new column by simply assigning the result of a vectorized operation to a new column name. Pandas automatically performs the multiplication element-wise for each row.\n",
    "***\n",
    "### Question 7: Applying a Function\n",
    "\n",
    "You have a DataFrame `df` with a 'Name' column. How would you create a new column 'Name_Length' that contains the length of each name?\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ab1823f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Name  Name_Length\n",
      "0      John            4\n",
      "1  Samantha            8\n",
      "2     Peter            5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Name': ['John', 'Samantha', 'Peter']})\n",
    "\n",
    "df['Name_Length'] = df['Name'].apply(len)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1e1e1f",
   "metadata": {},
   "source": [
    "**Explanation:** The `.apply()` method is used to apply a function to each element in a Series. Here, it applies Python's built-in `len()` function to every name in the 'Name' column.\n",
    "***\n",
    "### Question 8: Selection using `.loc` and `.iloc`\n",
    "\n",
    "Given the DataFrame `df`, explain how to select the element in the third row and second column using both `.loc` and `.iloc`. Assume the index is `[10, 20, 30, 40]`.\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db7135f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using .loc: 350\n",
      "Using .iloc: 350\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {'col1': [100, 200, 300, 400], 'col2': [150, 250, 350, 450]}\n",
    "df = pd.DataFrame(data, index=[10, 20, 30, 40])\n",
    "\n",
    "# Using .loc (label-based)\n",
    "val_loc = df.loc[30, 'col2']\n",
    "\n",
    "# Using .iloc (integer position-based)\n",
    "val_iloc = df.iloc[2, 1]\n",
    "\n",
    "print(f\"Using .loc: {val_loc}\")\n",
    "print(f\"Using .iloc: {val_iloc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fa388f",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "* `.loc` is used for **label-based** indexing. The label for the third row is `30` and the label for the second column is `'col2'`.\n",
    "* `.iloc` is used for **integer position-based** indexing. The third row is at integer position `2` (0-indexed) and the second column is at integer position `1`.\n",
    "***\n",
    "### Question 9: Value Counts\n",
    "\n",
    "You have a DataFrame `df` with a 'Category' column. How would you count the occurrences of each unique category?\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f19e6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\n",
      "A    3\n",
      "B    2\n",
      "C    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {'Category': ['A', 'B', 'A', 'C', 'B', 'A']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "category_counts = df['Category'].value_counts()\n",
    "print(category_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92e150d",
   "metadata": {},
   "source": [
    "**Explanation:** The `.value_counts()` method is a convenient Series method that returns a new Series containing the counts of unique values, sorted in descending order by default.\n",
    "***\n",
    "### Question 10: Dropping Columns\n",
    "\n",
    "Given a DataFrame `df`, how do you permanently remove the column named 'temp_data'?\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa4a1f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  1  3\n",
      "1  2  4\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['temp_data'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp_data\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m]}\n\u001b[0;32m     10\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[1;32m---> 12\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp_data\u001b[39m\u001b[38;5;124m'\u001b[39m, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "File \u001b[1;32mc:\\Users\\shiru\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5582\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5583\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5584\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5585\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5586\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5587\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5588\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5589\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\shiru\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\shiru\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\shiru\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['temp_data'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {'A': [1, 2], 'B': [3, 4], 'temp_data': [5, 6]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.drop('temp_data', axis = 1, inplace = True)\n",
    "\n",
    "print(df)\n",
    "\n",
    "data = {'A': [1, 2], 'B': [3, 4], 'temp_data': [5, 6]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.drop('temp_data', axis = 0, inplace = True)\n",
    "\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
